#!/usr/bin/env python3
from ast import literal_eval
from tokens import TokenError, TYPE, STRING, ID
from collections import OrderedDict
import lexical_analyzer
import datalog_parser
import relational_database


class DatalogInterpreter:
    """
    The most direct way to evaluate a rule is to use the mental model of an expression tree.
    Each predicate in the rule is evaluated as a query to return a relation.
    That relation returned by the predicate is then natural joined with the relations for other predicates in the rule.
    This process is best understood as a simple traversal of the rule, evaluating each predicate as a query,
    and then gathering the results with a natural join.
    """
    database = None
    relations = None
    rdbms = None
    rules = None

    def __init__(self, rdbms, rules):
        assert isinstance(rules, datalog_parser.Rules)
        self.rules = rules.rules
        assert isinstance(rdbms, relational_database.RDBMS)
        self.rdbms = rdbms
        self.relations = rdbms.relations
        self.database = rdbms.get_database()
        assert isinstance(self.database, OrderedDict)

        for rule in self.rules:
            print("Rule: " + str(rule))
            self.evaluate_rule(rule)

    def evaluate_rule(self, rule):
        relations = self.join(rule.predicates)
        print("RULE: " + str(rule))
        for r in relations:
            assert isinstance(r, relational_database.Relation)
            print("SCHEME:" + r.name[1])
            print(r)

    def join(self, predicates):
        assert isinstance(predicates, list)
        result = list()
        for predicate in predicates:
            result.extend(self.rdbms.evaluate_query(predicate))

        return result

    def union(self, head, joined):
        pass


def main(d_file, part=2, debug=False):
    result = ""
    if not (1 <= part <= 2):
        raise ValueError("Part must be either 1 or 2")

    if debug: result += ("Parsing '%s'" % d_file)

    # Create class objects
    tokens = lexical_analyzer.scan(d_file)

    if debug:
        datalog = datalog_parser.DatalogProgram(tokens)
    else:
        try:
            datalog = datalog_parser.DatalogProgram(tokens)
        except TokenError as t:
            return 'Failure!\n  (%s,"%s",%s)' % tuple(literal_eval(str(t)))

    # Get an initial database, we will add facts to it
    rdbms = relational_database.RDBMS(datalog)

    # Replace the original relations with the ones generated by the interpreter
    rdbms.relations = DatalogInterpreter(rdbms, datalog.rules).relations

    # TODO print number of passes through rules for schemes to be populated
    # After adding all the new facts,
    for datalog_query in datalog.queries.queries:
        # Each rule returns a new relation
        rdbms.evaluate_query(datalog_query)

    result += (str(rdbms))

    return result.rstrip("\n")


if __name__ == "__main__":
    """
    For part 1, this will perform single select, project, and rename operations for the file provided.  
    It will select the first query in the list and use it for all 3 operations, in succession
    
    For part 2, all queries will be analyzed and a thorough output will be printed
    """
    from argparse import ArgumentParser

    args = ArgumentParser(description="Run the datalog parser, this will produce output for lab 2")
    args.add_argument('-d', '--debug', action='store_true', default=False)
    args.add_argument('-p', '--part', help='A 1 or a 2.  Defaults to 2', default=2)
    args.add_argument('file', help='datalog file to parse')
    arg = args.parse_args()

    print(main(arg.file, part=int(arg.part), debug=arg.debug))
